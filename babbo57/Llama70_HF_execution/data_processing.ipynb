{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b97895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c938195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaricare i dataset originali\n",
    "\n",
    "prefix = \"data/original_datasets/\"\n",
    "\n",
    "raw_MB = pd.read_csv(prefix + \"dataset_Metabody.csv\")\n",
    "raw_ME = pd.read_csv(prefix + \"dataset_MetaEducation.csv\")\n",
    "raw_MI = pd.read_csv(prefix + \"dataset_MetaImagery.csv\")\n",
    "raw_MM = pd.read_csv(prefix + \"dataset_MoveMe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd24e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selezionare solo le colonne che ci interessano e rinominarle in modo standard\n",
    "\n",
    "clean_MB = raw_MB[[\"Metaphor\", \"Met_structure\", \"FamMetabody_Met\", \"SensMetabody_Met\", \"BodyMetabody_Met\"]]\n",
    "clean_MB.columns= [\"Metaphor\", \"Met_structure\", \"FAMILIARITY_human\", \"MEANINGFULNESS_human\", \"BODY_RELATEDNESS_human\"]\n",
    "clean_MB.to_csv(\"data/new_datasets/human_MB.csv\", index = False)\n",
    "\n",
    "clean_ME = raw_ME[[\"Metaphor\", \"Met_structure\", \"FAM(M)MetaEdu_Met\", \"MEA(M)MetaEdu_Met\", \"DIFF(M)MetaEdu_Met\"]]\n",
    "clean_ME.columns= [\"Metaphor\", \"Met_structure\", \"FAMILIARITY_human\", \"MEANINGFULNESS_human\", \"DIFFICULTY_human\"]\n",
    "clean_ME.to_csv(\"data/new_datasets/human_ME.csv\", index = False)\n",
    "\n",
    "clean_MI= raw_MI[[\"Metaphor\", \"Met_structure\", \"PhysMetaIma(M)_Met\", \"ImaMetaIma(M)_Met\"]]\n",
    "clean_MI.columns= [\"Metaphor\", \"Met_structure\", \"PHISICALITY_human\", \"IMAGEABILITY_human\"]\n",
    "clean_MI.to_csv(\"data/new_datasets/human_MI.csv\", index = False)\n",
    "\n",
    "clean_MM = raw_MM[[\"Metaphor\", \"Met_structure\", \"FamMoveme_Met\", \"SensMoveme_Met\"]]\n",
    "clean_MM.columns= [\"Metaphor\", \"Met_structure\", \"FAMILIARITY_human\", \"MEANINGFULNESS_human\"]\n",
    "clean_MM.to_csv(\"data/new_datasets/human_MM.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human_MB:        FAMILIARITY_human  MEANINGFULNESS_human  BODY_RELATEDNESS_human\n",
      "count          54.000000             64.000000               64.000000\n",
      "mean            4.062797              4.908003                4.019181\n",
      "std             1.231482              0.940674                1.734109\n",
      "min             1.846154              2.625000                1.346154\n",
      "25%             3.088942              4.311699                2.354167\n",
      "50%             4.118590              5.080128                3.807692\n",
      "75%             5.062500              5.509615                5.673077\n",
      "max             6.291667              6.384615                6.791667\n",
      "\n",
      "Human_ME:        FAMILIARITY_human  MEANINGFULNESS_human  DIFFICULTY_human\n",
      "count          80.000000             80.000000         80.000000\n",
      "mean            2.813966              3.588370          1.886662\n",
      "std             0.828771              0.598169          0.403041\n",
      "min             1.000000              2.333333          1.125000\n",
      "25%             2.333333              3.155000          1.598974\n",
      "50%             2.867446              3.666667          1.833333\n",
      "75%             3.333333              4.033929          2.166667\n",
      "max             4.214668              4.708333          3.142857\n",
      "\n",
      "Human_MI:        PHISICALITY_human  IMAGEABILITY_human\n",
      "count          42.000000           42.000000\n",
      "mean            3.275627            4.277221\n",
      "std             1.651698            1.030293\n",
      "min             1.263158            2.222222\n",
      "25%             1.912500            3.616228\n",
      "50%             2.973684            4.083333\n",
      "75%             4.236842            4.879386\n",
      "max             6.700000            6.500000\n",
      "\n",
      "Human_MM:        FAMILIARITY_human  MEANINGFULNESS_human\n",
      "count          60.000000             60.000000\n",
      "mean            4.643889              5.417241\n",
      "std             0.942199              0.754083\n",
      "min             2.600000              3.689655\n",
      "25%             4.116667              4.958333\n",
      "50%             4.666667              5.566667\n",
      "75%             5.316667              6.076724\n",
      "max             6.566667              6.533333\n"
     ]
    }
   ],
   "source": [
    "# Osservare le caratteristiche statistiche dei vari dataset umani\n",
    "\n",
    "prefix = \"data/human_datasets/\"\n",
    "\n",
    "human_MB = pd.read_csv(prefix + \"human_MB.csv\")\n",
    "human_values_MB = human_MB[[\"FAMILIARITY_human\", \"MEANINGFULNESS_human\", \"BODY_RELATEDNESS_human\"]]\n",
    "human_values_MB = human_values_MB.replace(\",\", \".\", regex=True)\n",
    "print(\"\\nHuman_MB:\", human_values_MB.describe())\n",
    "\n",
    "human_ME = pd.read_csv(prefix + \"human_ME.csv\")\n",
    "human_values_ME = human_ME[[\"FAMILIARITY_human\", \"MEANINGFULNESS_human\", \"DIFFICULTY_human\"]]\n",
    "human_values_ME = human_values_ME.replace(\",\", \".\", regex=True)\n",
    "human_values_ME = human_values_ME.astype(float)\n",
    "print(\"\\nHuman_ME:\", human_values_ME.describe())\n",
    "\n",
    "human_MI = pd.read_csv(prefix + \"human_MI.csv\")\n",
    "human_values_MI = human_MI[[\"PHISICALITY_human\", \"IMAGEABILITY_human\"]]\n",
    "human_values_MI = human_values_MI.replace(\",\", \".\", regex=True)\n",
    "human_values_MI = human_values_MI.astype(float)\n",
    "print(\"\\nHuman_MI:\", human_values_MI.describe())\n",
    "\n",
    "human_MM = pd.read_csv(prefix + \"human_MM.csv\")\n",
    "human_values_MM = human_MM[[\"FAMILIARITY_human\", \"MEANINGFULNESS_human\"]]\n",
    "human_values_MM = human_values_MM.replace(\",\", \".\", regex=True)\n",
    "human_values_MM = human_values_MM.astype(float)\n",
    "print(\"\\nHuman_MM:\", human_values_MM.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec9483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "synthetic_MB:\n",
      "        annotator  FAMILIARITY_synthetic  MEANINGFULNESS_synthetic  \\\n",
      "count       64.0              64.000000                 64.000000   \n",
      "mean         1.0               3.859375                  5.234375   \n",
      "std          0.0               0.940570                  0.771356   \n",
      "min          1.0               2.000000                  3.000000   \n",
      "25%          1.0               3.000000                  5.000000   \n",
      "50%          1.0               4.000000                  5.000000   \n",
      "75%          1.0               4.000000                  6.000000   \n",
      "max          1.0               6.000000                  7.000000   \n",
      "\n",
      "       BODY_RELATEDNESS_synthetic  \n",
      "count                   64.000000  \n",
      "mean                     3.875000  \n",
      "std                      2.994704  \n",
      "min                      1.000000  \n",
      "25%                      1.000000  \n",
      "50%                      1.000000  \n",
      "75%                      7.000000  \n",
      "max                      7.000000  \n"
     ]
    }
   ],
   "source": [
    "# Osservare le caratteristiche statistiche dei vari dataset sintetici per il dato modello\n",
    "\n",
    "prefix = \"data/synthetic_datasets/\"\n",
    "model = \"_llama-3.3-70b-versatile_\"\n",
    "\n",
    "synthetic_MB = pd.read_csv(prefix + \"synthetic_MB\" + model + \".csv\")\n",
    "synthetic_values_MB = synthetic_MB[[\"annotator\", \"FAMILIARITY_synthetic\", \"MEANINGFULNESS_synthetic\", \"BODY_RELATEDNESS_synthetic\"]]\n",
    "synthetic_values_MB = synthetic_values_MB.replace(\",\", \".\", regex=True)\n",
    "synthetic_values_MB = synthetic_values_MB.astype(float)\n",
    "synthetic_values_MB_SINGLE_RUN = synthetic_values_MB[synthetic_values_MB[\"annotator\"] == 1]\n",
    "\n",
    "print(\"\\nsynthetic_MB:\\n\", synthetic_values_MB_SINGLE_RUN.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4cafc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB: \n",
      " unused_familiarity_MB:  25 unused_meaningfulness_MB:  59 unused_body_relatedness_MB:  64 \n",
      "\n",
      "ME: \n",
      " unused_familiarity_ME:  32 unused_meaningfulness_ME:  38 unused_difficulty_ME:  34 \n",
      "\n",
      "MI: \n",
      " unused_phisicality_MI:  15 unused_imageability_MI:  40 \n",
      "\n",
      "MM: \n",
      " unused_familiarity_MM:  60 unused_meaningfulness_MM:  60 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rintracciare le metafore già usate in altri studi quanto a specifiche dimensioni\n",
    "\n",
    "df_dict = {\"MB\" : raw_MB , \"ME\" : raw_ME, \"MI\" : raw_MI, \"MM\" : raw_MM}\n",
    "used_metaphors_MB = {\"FAMILIARITY\" : set(), \"MEANINGFULNESS\" : set(), \"BODY_RELATEDNESS\" : set()}\n",
    "used_metaphors_ME = {\"FAMILIARITY\" : set(), \"MEANINGFULNESS\" : set(), \"DIFFICULTY\" : set()}\n",
    "used_metaphors_MI = {\"PHISICALITY\" : set(), \"IMAGEABILITY\" : set()}\n",
    "used_metaphors_MM = {\"FAMILIARITY\" : set(), \"MEANINGFULNESS\" : set()}\n",
    "\n",
    "for name, df in df_dict.items():\n",
    "\n",
    "  if name == \"MB\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"Bambini et al. (2013)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_MB[\"MEANINGFULNESS\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if  row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Lago et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_familiarity_MB = used_metaphors_MB[\"FAMILIARITY\"]\n",
    "    used_meaningfulness_MB = used_metaphors_MB[\"MEANINGFULNESS\"]\n",
    "    used_body_relatedness = used_metaphors_MB[\"BODY_RELATEDNESS\"]\n",
    "\n",
    "    unused_familiarity_MB = all_metaphors - used_familiarity_MB\n",
    "    unused_meaningfulness_MB = all_metaphors - used_meaningfulness_MB\n",
    "    unused_body_relatedness_MB = all_metaphors - used_body_relatedness\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_familiarity_MB: \", len(unused_familiarity_MB),\n",
    "      \"unused_meaningfulness_MB: \", len(unused_meaningfulness_MB),\n",
    "      \"unused_body_relatedness_MB: \", len(unused_body_relatedness_MB),\n",
    "      \"\\n\"\n",
    "    )\n",
    "\n",
    "  if name == \"ME\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"Bambini et al. (2013)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_ME[\"MEANINGFULNESS\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_ME[\"DIFFICULTY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if  row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_ME[\"DIFFICULTY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Lago et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_familiarity_ME = used_metaphors_ME[\"FAMILIARITY\"]\n",
    "    used_meaningfulness_ME = used_metaphors_ME[\"MEANINGFULNESS\"]\n",
    "    used_difficulty_ME = used_metaphors_ME[\"DIFFICULTY\"]\n",
    "\n",
    "    unused_familiarity_ME = all_metaphors - used_familiarity_ME\n",
    "    unused_meaningfulness_ME = all_metaphors - used_meaningfulness_ME\n",
    "    unused_difficulty_ME = all_metaphors - used_difficulty_ME\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_familiarity_ME: \", len(unused_familiarity_ME),\n",
    "      \"unused_meaningfulness_ME: \", len(unused_meaningfulness_ME),\n",
    "      \"unused_difficulty_ME: \", len(unused_difficulty_ME),\n",
    "      \"\\n\"\n",
    "    )\n",
    "\n",
    "  if name == \"MI\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_MI[\"PHISICALITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MI[\"IMAGEABILITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_phisicality_MI = used_metaphors_MI[\"PHISICALITY\"]\n",
    "    used_imageability_MI = used_metaphors_MI[\"IMAGEABILITY\"]\n",
    "\n",
    "    unused_phisicality_MI = all_metaphors - used_phisicality_MI\n",
    "    unused_imageability_MI = all_metaphors - used_imageability_MI\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_phisicality_MI: \", len(unused_phisicality_MI),\n",
    "      \"unused_imageability_MI: \", len(unused_imageability_MI),\n",
    "      \"\\n\"\n",
    "    )\n",
    "\n",
    "  if name == \"MM\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"Bambini et al. (2013)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_MM[\"MEANINGFULNESS\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Lago et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_familiarity_MM = used_metaphors_MM[\"FAMILIARITY\"]\n",
    "    used_meaningfulness_MM = used_metaphors_MM[\"MEANINGFULNESS\"]\n",
    "\n",
    "    unused_familiarity_MM = all_metaphors - used_familiarity_MM\n",
    "    unused_meaningfulness_MM = all_metaphors - used_meaningfulness_MM\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_familiarity_MM: \", len(unused_familiarity_MM),\n",
    "      \"unused_meaningfulness_MM: \", len(unused_meaningfulness_MM),\n",
    "      \"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c70710",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexingError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# USED FAMILIARITY\u001b[39;00m\n\u001b[32m     52\u001b[39m USED_fixed_human_values_MB = fixed_human_values_MB.loc[USED_MASK_FAMILIARITY]\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m USED_fixed_synthetic_values_MB_SINGLE_RUN = \u001b[43mfixed_synthetic_values_MB_SINGLE_RUN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mUSED_MASK_FAMILIARITY\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     54\u001b[39m USED_fixed_synthetic_values_MB_AGGREGATED = fixed_synthetic_values_MB_AGGREGATED.loc[USED_MASK_FAMILIARITY]\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# human vs synthetic SINGLE_RUN\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1192\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1190\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1191\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1414\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_slice_axis(key, axis=axis)\n\u001b[32m   1413\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1210\u001b[39m, in \u001b[36m_LocationIndexer._getbool_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1206\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getbool_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: AxisInt):\n\u001b[32m   1208\u001b[39m     \u001b[38;5;66;03m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[32m   1209\u001b[39m     labels = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m     key = \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1211\u001b[39m     inds = key.nonzero()[\u001b[32m0\u001b[39m]\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._take_with_is_copy(inds, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:2698\u001b[39m, in \u001b[36mcheck_bool_indexer\u001b[39m\u001b[34m(index, key)\u001b[39m\n\u001b[32m   2696\u001b[39m indexer = result.index.get_indexer_for(index)\n\u001b[32m   2697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m -\u001b[32m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[32m-> \u001b[39m\u001b[32m2698\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[32m   2699\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnalignable boolean Series provided as \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2700\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mindexer (index of the boolean Series and of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2701\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe indexed object do not match).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2702\u001b[39m     )\n\u001b[32m   2704\u001b[39m result = result.take(indexer)\n\u001b[32m   2706\u001b[39m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[31mIndexingError\u001b[39m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "# CORRELAZIONI STATISTICHE\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Definizione dei percorsi che portano ai dati + lettura dei dati\n",
    "\n",
    "prefix = \"data/human_datasets/\"\n",
    "human_MB = pd.read_csv(prefix + \"human_MB.csv\")\n",
    "\n",
    "prefix = \"data/synthetic_datasets/\"\n",
    "model = \"_meta-llama-Llama-3.3-70B-Instruct_\"\n",
    "synthetic_MB = pd.read_csv(prefix + \"synthetic_MB\" + model + \".csv\")\n",
    "\n",
    "# Definizione della funzione che processa i valori in modo che siano trattabili per i calcoli statistici\n",
    "\n",
    "def preparing_4_stat(df):\n",
    "\n",
    "    if df.columns[0] == \"Metaphor\":\n",
    "        output_df = df.iloc[:, 2:]\n",
    "\n",
    "    else:\n",
    "        output_df = df.iloc[:, 3:]\n",
    "\n",
    "    output_df = output_df.replace(\",\", \".\", regex=True)\n",
    "    output_df = output_df.astype(float)\n",
    "\n",
    "    return output_df\n",
    "\n",
    "# MB:\n",
    "\n",
    "# FAMILIARITY\n",
    "# Non tutte le metafore di MB erano state giudicate quanto alla dimensione di familiarità, quindi nel calcolare la correlazione tra familiarità umana e familiarità sintetica i dataset vanno epurati da tali metafore\n",
    "\n",
    "no_familiarity_metaphors_MB = human_MB[human_MB[\"FAMILIARITY_human\"].isna() | (human_MB[\"FAMILIARITY_human\"] == \"\")]\n",
    "\n",
    "fixed_human_MB = human_MB.drop(no_familiarity_metaphors_MB.index)\n",
    "fixed_synthetic_MB = synthetic_MB.drop(no_familiarity_metaphors_MB.index)\n",
    "\n",
    "# Definire le maschere USED e UNUSED prima di togliere la colonna \"Metaphor\" applicando la funzione preparing_4_stat()\n",
    "USED_MASK_FAMILIARITY = fixed_human_MB[\"Metaphor\"].isin(used_familiarity_MB)\n",
    "UNUSED_MASK_FAMILIARITY = fixed_human_MB[\"Metaphor\"].isin(unused_familiarity_MB)\n",
    "\n",
    "fixed_human_values_MB = preparing_4_stat(fixed_human_MB)\n",
    "\n",
    "fixed_synthetic_MB_SINGLE_RUN = fixed_synthetic_MB[fixed_synthetic_MB[\"annotator\"] == 1]\n",
    "fixed_synthetic_values_MB_SINGLE_RUN = preparing_4_stat(fixed_synthetic_MB)\n",
    "\n",
    "fixed_synthetic_MB_AGGREGATED = (fixed_synthetic_MB.groupby([\"annotator\", \"metaphor\", \"metaphor_structure\"], as_index=False)[[\"FAMILIARITY_synthetic\", \"MEANINGFULNESS_synthetic\", \"BODY_RELATEDNESS_synthetic\"]].mean())\n",
    "fixed_synthetic_values_MB_AGGREGATED = preparing_4_stat(fixed_synthetic_MB_AGGREGATED)\n",
    "\n",
    "# USED FAMILIARITY\n",
    "USED_fixed_human_values_MB = fixed_human_values_MB.loc[USED_MASK_FAMILIARITY]\n",
    "USED_fixed_synthetic_values_MB_SINGLE_RUN = fixed_synthetic_values_MB_SINGLE_RUN.loc[USED_MASK_FAMILIARITY]\n",
    "USED_fixed_synthetic_values_MB_AGGREGATED = fixed_synthetic_values_MB_AGGREGATED.loc[USED_MASK_FAMILIARITY]\n",
    "\n",
    "# human vs synthetic SINGLE_RUN\n",
    "rho, p_value = stats.spearmanr(USED_fixed_human_values_MB[\"FAMILIARITY_human\"], USED_fixed_synthetic_values_MB_SINGLE_RUN[\"FAMILIARITY_synthetic\"])\n",
    "print(\"\\nUSED FAMILIARITY - SINGLE_RUN:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# human vs synthetic AGGREGATED\n",
    "rho, p_value = stats.spearmanr(USED_fixed_human_values_MB[\"FAMILIARITY_human\"], USED_fixed_synthetic_values_MB_AGGREGATED[\"FAMILIARITY_synthetic\"])\n",
    "print(\"\\nUSED FAMILIARITY - AGGREGATED:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# UNUSED FAMILIARITY\n",
    "UNUSED_fixed_human_values_MB = fixed_human_values_MB.loc[UNUSED_MASK_FAMILIARITY]\n",
    "UNUSED_fixed_synthetic_values_MB_SINGLE_RUN = fixed_synthetic_values_MB_SINGLE_RUN.loc[UNUSED_MASK_FAMILIARITY]\n",
    "UNUSED_fixed_synthetic_values_MB_AGGREGATED = fixed_synthetic_values_MB_AGGREGATED.loc[UNUSED_MASK_FAMILIARITY]\n",
    "\n",
    "# human vs synthetic SINGLE_RUN\n",
    "rho, p_value = stats.spearmanr(UNUSED_fixed_human_values_MB[\"FAMILIARITY_human\"], UNUSED_fixed_synthetic_values_MB_SINGLE_RUN[\"FAMILIARITY_synthetic\"])\n",
    "print(\"\\nUNUSED FAMILIARITY - SINGLE_RUN:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# human vs synthetic AGGREGATED\n",
    "rho, p_value = stats.spearmanr(UNUSED_fixed_human_values_MB[\"FAMILIARITY_human\"], UNUSED_fixed_synthetic_values_MB_AGGREGATED[\"FAMILIARITY_synthetic\"])\n",
    "print(\"\\nUNUSED FAMILIARITY - AGGREGATED:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# MEANINGFULNESS e BODY_RELATEDNESS:\n",
    "\n",
    "# Definire le maschere USED e UNUSED prima di togliere la colonna \"Metaphor\" applicando la funzione preparing_4_stat()\n",
    "USED_MASK_MEANINGFULNESS = human_MB[\"Metaphor\"].isin(used_meaningfulness_MB)\n",
    "UNUSED_MASK_MEANINGFULNESS = human_MB[\"Metaphor\"].isin(unused_meaningfulness_MB)\n",
    "\n",
    "USED_MASK_BODY_RELATEDNESS = human_MB[\"Metaphor\"].isin(used_meaningfulness_MB)\n",
    "UNUSED_MASK_BODY_RELAREDNESS = human_MB[\"Metaphor\"].isin(unused_meaningfulness_MB)\n",
    "\n",
    "human_values_MB = preparing_4_stat(human_MB)\n",
    "\n",
    "synthetic_MB_SINGLE_RUN = synthetic_MB[synthetic_MB[\"annotator\"] == 1]\n",
    "synthetic_values_MB_SINGLE_RUN = preparing_4_stat(synthetic_MB_SINGLE_RUN)\n",
    "\n",
    "synthetic_MB_AGGREGATED = (synthetic_MB.groupby([\"annotator\", \"metaphor\", \"metaphor_structure\"], as_index=False)[[\"FAMILIARITY_synthetic\", \"MEANINGFULNESS_synthetic\", \"BODY_RELATEDNESS_synthetic\"]].mean())\n",
    "synthetic_values_MB_AGGREGATED = preparing_4_stat(synthetic_MB_AGGREGATED)\n",
    "\n",
    "# USED MEANINGFULNESS\n",
    "\n",
    "USED_human_values_MB = human_values_MB.loc[USED_MASK_MEANINGFULNESS]\n",
    "USED_synthetic_values_MB_SINGLE_RUN = synthetic_values_MB_SINGLE_RUN.loc[USED_MASK_MEANINGFULNESS]\n",
    "USED_synthetic_values_MB_AGGREGATED = synthetic_values_MB_AGGREGATED.loc[USED_MASK_MEANINGFULNESS]\n",
    "\n",
    "# human vs synthetic SINGLE_RUN\n",
    "rho, p_value = stats.spearmanr(USED_human_values_MB[\"MEANINGFULNESS_human\"], USED_synthetic_values_MB_SINGLE_RUN[\"MEANINGFULNESS_synthetic\"])\n",
    "print(\"\\nUSED MEANINGFULNESS - SINGLE_RUN:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# human vs synthetic AGGREGATED\n",
    "rho, p_value = stats.spearmanr(USED_human_values_MB[\"MEANINGFULNESS_human\"], USED_synthetic_values_MB_AGGREGATED[\"MEANINGFULNESS_synthetic\"])\n",
    "print(\"\\nUSED MEANINGFULNESS - AGGREGATED:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# UNUSED MEANINGFULNESS\n",
    "\n",
    "UNUSED_human_values_MB = human_values_MB.loc[UNUSED_MASK_MEANINGFULNESS]\n",
    "UNUSED_synthetic_values_MB_SINGLE_RUN = synthetic_values_MB_SINGLE_RUN.loc[UNUSED_MASK_MEANINGFULNESS]\n",
    "UNUSED_synthetic_values_AGGREGATED = synthetic_values_MB_AGGREGATED.loc[UNUSED_MASK_MEANINGFULNESS]\n",
    "\n",
    "# human vs synthetic SINGLE RUN\n",
    "rho, p_value = stats.spearmanr(UNUSED_human_values_MB[\"MEANINGFULNESS_human\"], UNUSED_synthetic_values_MB_SINGLE_RUN[\"MEANINGFULNESS_synthetic\"])\n",
    "print(\"\\nUNUSED MEANINGFULNESS - SINGLE_RUN:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# human vs synthetic AGGREGATED\n",
    "rho, p_value = stats.spearmanr(UNUSED_human_values_MB[\"MEANINGFULNESS_human\"], UNUSED_synthetic_values_AGGREGATED[\"MEANINGFULNESS_synthetic\"])\n",
    "print(\"\\nUNUSED MEANINGFULNESS - AGGREGATED:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# USED BODY_RELATEDNESS\n",
    "\n",
    "USED_human_values_MB = human_values_MB.loc[USED_MASK_BODY_RELATEDNESS]\n",
    "USED_synthetic_values_MB_SINGLE_RUN = synthetic_values_MB_SINGLE_RUN.loc[USED_MASK_BODY_RELATEDNESS]\n",
    "USED_synthetic_values_MB_AGGREGATED = synthetic_values_MB_AGGREGATED.loc[USED_MASK_BODY_RELATEDNESS]\n",
    "\n",
    "# human vs synthetic SINGLE RUN\n",
    "rho, p_value = stats.spearmanr(USED_human_values_MB[\"BODY_RELATEDNESS_human\"], USED_synthetic_values_MB_SINGLE_RUN[\"BODY_RELATEDNESS_synthetic\"])\n",
    "print(\"\\nUSED BODY_RELATEDNESS - SINGLE_RUN:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# human vs synthetic AGGREGATED\n",
    "rho, p_value = stats.spearmanr(USED_human_values_MB[\"BODY_RELATEDNESS_human\"], USED_synthetic_values_MB_AGGREGATED[\"BODY_RELATEDNESS_synthetic\"])\n",
    "print(\"\\nUSED BODY_RELATEDNESS - AGGREGATED:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#UNUSED BODY_RELATEDNESS\n",
    "UNUSED_human_values_MB = human_values_MB.loc[UNUSED_MASK_BODY_RELAREDNESS]\n",
    "UNUSED_synthetic_values_MB_SINGLE_RUN = synthetic_values_MB_SINGLE_RUN.loc[UNUSED_MASK_BODY_RELAREDNESS]\n",
    "UNUSED_synthetic_values_MB_AGGREGATED = synthetic_values_MB_AGGREGATED.loc[UNUSED_MASK_BODY_RELAREDNESS]\n",
    "\n",
    "# human vs synthetic SINGLE RUN\n",
    "rho, p_value = stats.spearmanr(UNUSED_human_values_MB[\"BODY_RELATEDNESS_human\"], UNUSED_synthetic_values_MB_SINGLE_RUN[\"BODY_RELATEDNESS_synthetic\"])\n",
    "print(\"\\nUNUSED BODY_RELATEDNESS - SINGLE RUN:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# human vs synthetic AGGREGATED\n",
    "rho, p_value = stats.spearmanr(UNUSED_human_values_MB[\"BODY_RELATEDNESS_human\"], UNUSED_synthetic_values_MB_AGGREGATED[\"BODY_RELATEDNESS_synthetic\"])\n",
    "print(\"\\nUNUSED BODY_RELATEDNESS - AGGREGATED:\")\n",
    "print(\"Spearman correlation coefficient:\", rho, \"\\np-value: \", p_value)\n",
    "if p_value > 0.05:\n",
    "    print(\"p-value TROPPO ALTO\", \"\\n\\n\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b53374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenare pezzi di dataset sintetici\n",
    "\n",
    "prefix = \"data/synthetic_datasets/\"\n",
    "model = \"_meta-llama-Llama-3.3-70B-Instruct_\"\n",
    "synthetic_MB_1 = pd.read_csv(prefix + \"synthetic_MB\" + model + str(1) + \".csv\")\n",
    "synthetic_MB_2 = pd.read_csv(prefix + \"synthetic_MB\" + model + str(2) + \".csv\")\n",
    "synthetic_MB = pd.concat([synthetic_MB_1, synthetic_MB_2])\n",
    "synthetic_MB.to_csv(prefix + \"synthetic_MB\" + model + \".csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
