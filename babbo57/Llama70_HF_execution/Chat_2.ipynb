{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8729bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44dd37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB\n",
      "MB\n",
      "MB\n",
      "MB\n",
      "MB\n",
      "MB\n",
      "MB\n",
      "MB\n",
      "MB\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "ME\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MI\n",
      "MM\n",
      "MM\n",
      "MM\n",
      "MM\n",
      "MM\n",
      "MM\n",
      "MM\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'IUSS NEPLab MetaImagery study'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'IUSS NEPLab MetaImagery study'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mMM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     31\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[33m\"\u001b[39m\u001b[33mIUSS NEPLab MetaBody study\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mY\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m row[\u001b[33m\"\u001b[39m\u001b[33mIUSS NEPLab MetaEducation study\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mY\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIUSS NEPLab MetaImagery study\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m\"\u001b[39m\u001b[33mY\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     34\u001b[39m       \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMM\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1133\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1249\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'IUSS NEPLab MetaImagery study'"
     ]
    }
   ],
   "source": [
    "# Per capire se ci sono metafore in comune tra i 4 studi\n",
    "\n",
    "raw_path = \"data/original_datasets/\"\n",
    "df_dict = {\"MB\" : pd.read_csv(raw_path + \"raw_MB.csv\") , \"ME\" : pd.read_csv(raw_path + \"raw_ME.csv\"), \"MI\" : pd.read_csv(raw_path + \"raw_MI.csv\"), \"MM\" : pd.read_csv(raw_path + \"raw_MI.csv\")}\n",
    "\n",
    "for name, df in df_dict.items():\n",
    "\n",
    "  if name == \"MB\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"IUSS NEPLab MetaEducation study\"] == \"Y\" or row[\"IUSS NEPLab MetaImagery study\"] == \"Y\" or row[\"IUSS NEPLab MoveMe study\"] == \"Y\":\n",
    "        print(\"MB\")\n",
    "\n",
    "  if name == \"ME\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"IUSS NEPLab MetaBody study\"] == \"Y\" or row[\"IUSS NEPLab MetaImagery study\"] == \"Y\" or row[\"IUSS NEPLab MoveMe study\"] == \"Y\":\n",
    "        print(\"ME\")\n",
    "\n",
    "  if name == \"MI\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"IUSS NEPLab MetaBody study\"] == \"Y\" or row[\"IUSS NEPLab MetaEducation study\"] == \"Y\" or row[\"IUSS NEPLab MoveMe study\"] == \"Y\":\n",
    "        print(\"MI\")\n",
    "\n",
    "  if name == \"MM\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"IUSS NEPLab MetaBody study\"] == \"Y\" or row[\"IUSS NEPLab MetaEducation study\"] == \"Y\" or row[\"IUSS NEPLab MetaImagery study\"] == \"Y\":\n",
    "        print(\"MM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8151b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB: \n",
      " unused_familiarity_MB:  25 unused_meaningfulness_MB:  59 unused_body_relatedness_MB:  64 \n",
      "\n",
      "ME: \n",
      " unused_familiarity_ME:  32 unused_meaningfulness_ME:  38 unused_difficulty_ME:  34 \n",
      "\n",
      "MI: \n",
      " unused_phisicality_MI:  15 unused_imageability_MI:  40 \n",
      "\n",
      "MM: \n",
      " unused_familiarity_MM:  2 unused_meaningfulness_MM:  32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rintracciare le metafore già usate in altri studi quanto a specifiche dimensioni\n",
    "\n",
    "raw_path = \"data/original_datasets/\"\n",
    "df_dict = {\"MB\" : pd.read_csv(raw_path + \"raw_MB.csv\") , \"ME\" : pd.read_csv(raw_path + \"raw_ME.csv\"), \"MI\" : pd.read_csv(raw_path + \"raw_MI.csv\"), \"MM\" : pd.read_csv(raw_path + \"raw_MI.csv\")}\n",
    "used_metaphors_MB = {\"FAMILIARITY\" : set(), \"MEANINGFULNESS\" : set(), \"BODY_RELATEDNESS\" : set()}\n",
    "used_metaphors_ME = {\"FAMILIARITY\" : set(), \"MEANINGFULNESS\" : set(), \"DIFFICULTY\" : set()}\n",
    "used_metaphors_MI = {\"PHISICALITY\" : set(), \"IMAGEABILITY\" : set()}\n",
    "used_metaphors_MM = {\"FAMILIARITY\" : set(), \"MEANINGFULNESS\" : set()}\n",
    "\n",
    "for name, df in df_dict.items():\n",
    "\n",
    "  if name == \"MB\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "      \n",
    "      if row[\"Bambini et al. (2013)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_MB[\"MEANINGFULNESS\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if  row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Lago et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MB[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_familiarity_MB = used_metaphors_MB[\"FAMILIARITY\"]\n",
    "    used_meaningfulness_MB = used_metaphors_MB[\"MEANINGFULNESS\"]\n",
    "    used_body_relatedness = used_metaphors_MB[\"BODY_RELATEDNESS\"]\n",
    "\n",
    "    unused_familiarity_MB = all_metaphors - used_familiarity_MB\n",
    "    unused_meaningfulness_MB = all_metaphors - used_meaningfulness_MB\n",
    "    unused_body_relatedness_MB = all_metaphors - used_body_relatedness\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_familiarity_MB: \", len(unused_familiarity_MB),\n",
    "      \"unused_meaningfulness_MB: \", len(unused_meaningfulness_MB),\n",
    "      \"unused_body_relatedness_MB: \", len(unused_body_relatedness_MB),\n",
    "      \"\\n\"\n",
    "    )\n",
    "\n",
    "  if name == \"ME\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"Bambini et al. (2013)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_ME[\"MEANINGFULNESS\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_ME[\"DIFFICULTY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if  row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_ME[\"DIFFICULTY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Lago et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_ME[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_familiarity_ME = used_metaphors_ME[\"FAMILIARITY\"]\n",
    "    used_meaningfulness_ME = used_metaphors_ME[\"MEANINGFULNESS\"]\n",
    "    used_difficulty_ME = used_metaphors_ME[\"DIFFICULTY\"]\n",
    "\n",
    "    unused_familiarity_ME = all_metaphors - used_familiarity_ME\n",
    "    unused_meaningfulness_ME = all_metaphors - used_meaningfulness_ME\n",
    "    unused_difficulty_ME = all_metaphors - used_difficulty_ME\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_familiarity_ME: \", len(unused_familiarity_ME),\n",
    "      \"unused_meaningfulness_ME: \", len(unused_meaningfulness_ME),\n",
    "      \"unused_difficulty_ME: \", len(unused_difficulty_ME),\n",
    "      \"\\n\"\n",
    "    )\n",
    "\n",
    "  if name == \"MI\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_MI[\"PHISICALITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MI[\"IMAGEABILITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_phisicality_MI = used_metaphors_MI[\"PHISICALITY\"]\n",
    "    used_imageability_MI = used_metaphors_MI[\"IMAGEABILITY\"]\n",
    "\n",
    "    unused_phisicality_MI = all_metaphors - used_phisicality_MI\n",
    "    unused_imageability_MI = all_metaphors - used_imageability_MI\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_phisicality_MI: \", len(unused_phisicality_MI),\n",
    "      \"unused_imageability_MI: \", len(unused_imageability_MI),\n",
    "      \"\\n\"\n",
    "    )\n",
    "\n",
    "  if name == \"MM\":\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "      if row[\"Bambini et al. (2013)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "        used_metaphors_MM[\"MEANINGFULNESS\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Canal et al. (2022)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    " \n",
    "      if row[\"Bambini et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "      if row[\"Lago et al. (2024)\"] == \"Y\":\n",
    "        used_metaphors_MM[\"FAMILIARITY\"].add(row[\"Metaphor\"])\n",
    "\n",
    "    all_metaphors = set(df[\"Metaphor\"])\n",
    "    used_familiarity_MM = used_metaphors_MM[\"FAMILIARITY\"]\n",
    "    used_meaningfulness_MM = used_metaphors_MM[\"MEANINGFULNESS\"]\n",
    "\n",
    "    unused_familiarity_MM = all_metaphors - used_familiarity_MM\n",
    "    unused_meaningfulness_MM = all_metaphors - used_meaningfulness_MM\n",
    "\n",
    "    print(name + \": \\n\",\n",
    "      \"unused_familiarity_MM: \", len(unused_familiarity_MM),\n",
    "      \"unused_meaningfulness_MM: \", len(unused_meaningfulness_MM),\n",
    "      \"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0783adad",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: FAMILIARITY_human'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m         dim_name = dim.replace(\u001b[33m\"\u001b[39m\u001b[33m_human\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m         unused_set = unused_metaphors[dataset][dim_name]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m         all_results[dataset][dim_name] = \u001b[43mcompute_correlations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuman_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynthetic_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munused_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Stampa risultati\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset, dims \u001b[38;5;129;01min\u001b[39;00m all_results.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mcompute_correlations\u001b[39m\u001b[34m(human_df, synthetic_df, dimension, unused_set)\u001b[39m\n\u001b[32m     40\u001b[39m human_df[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m] = human_df[\u001b[33m'\u001b[39m\u001b[33mMetaphor\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[33m'\u001b[39m\u001b[33munused\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m unused_set \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mused\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Media dei 10 annotatori sintetici\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m synthetic_mean = \u001b[43msynthetic_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmetaphor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m]\u001b[49m.mean().reset_index()\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Annotatore 1\u001b[39;00m\n\u001b[32m     46\u001b[39m synthetic_1 = synthetic_df[synthetic_df[\u001b[33m'\u001b[39m\u001b[33mannotator\u001b[39m\u001b[33m'\u001b[39m]==\u001b[32m1\u001b[39m][[\u001b[33m'\u001b[39m\u001b[33mmetaphor\u001b[39m\u001b[33m'\u001b[39m, dimension]].rename(columns={dimension:\u001b[33m'\u001b[39m\u001b[33msynthetic_1\u001b[39m\u001b[33m'\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[39m, in \u001b[36mDataFrameGroupBy.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) > \u001b[32m1\u001b[39m:\n\u001b[32m   1945\u001b[39m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[32m   1947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1950\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacop\\OneDrive\\Desktop\\Metaphorical-ratings-LLMs-replication-study\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:245\u001b[39m, in \u001b[36mSelectionMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    246\u001b[39m     ndim = \u001b[38;5;28mself\u001b[39m.obj[key].ndim\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gotitem(key, ndim=ndim)\n",
      "\u001b[31mKeyError\u001b[39m: 'Column not found: FAMILIARITY_human'"
     ]
    }
   ],
   "source": [
    "# Percorsi\n",
    "human_path = \"data/human_datasets/\"\n",
    "synthetic_path = \"data/synthetic_datasets/\"\n",
    "\n",
    "# Dati umani\n",
    "human_files = {\n",
    "    \"MB\": \"human_MB.csv\",\n",
    "    \"ME\": \"human_ME.csv\",\n",
    "    \"MI\": \"human_MI.csv\",\n",
    "    \"MM\": \"human_MM.csv\"\n",
    "}\n",
    "\n",
    "human_dfs = {k: pd.read_csv(human_path + v, decimal=',') for k, v in human_files.items()}\n",
    "\n",
    "# Dati sintetici\n",
    "synthetic_files = {\n",
    "    \"MB\": \"synthetic_MB_meta-llama-Llama-3.3-70B-Instruct_.csv\",\n",
    "    \"ME\": \"synthetic_ME_meta-llama-Llama-3.3-70B-Instruct_.csv\",\n",
    "    \"MI\": \"synthetic_MI_meta-llama-Llama-3.3-70B-Instruct_.csv\",\n",
    "    \"MM\": \"synthetic_MM_meta-llama-Llama-3.3-70B-Instruct_.csv\"\n",
    "}\n",
    "\n",
    "synthetic_dfs = {k: pd.read_csv(synthetic_path + v) for k, v in synthetic_files.items()}\n",
    "\n",
    "# Dizionari usate/non usate\n",
    "# Esempio da te fornito, qui devi avere i set già calcolati\n",
    "unused_metaphors = {\n",
    "    \"MB\": {\"FAMILIARITY\": unused_familiarity_MB, \"MEANINGFULNESS\": unused_meaningfulness_MB, \"BODY_RELATEDNESS\": unused_body_relatedness_MB},\n",
    "    \"ME\": {\"FAMILIARITY\": unused_familiarity_ME, \"MEANINGFULNESS\": unused_meaningfulness_ME, \"DIFFICULTY\": unused_difficulty_ME},\n",
    "    \"MI\": {\"PHISICALITY\": unused_phisicality_MI, \"IMAGEABILITY\": unused_imageability_MI},\n",
    "    \"MM\": {\"FAMILIARITY\": unused_familiarity_MM, \"MEANINGFULNESS\": unused_meaningfulness_MM}\n",
    "}\n",
    "\n",
    "# Funzione per calcolare correlazioni\n",
    "def compute_correlations(human_df, synthetic_df, dimension, unused_set):\n",
    "    # Filtra solo metafore con valori non NaN\n",
    "    human_df = human_df[['Metaphor', dimension]].dropna()\n",
    "    \n",
    "    # Identifica metafore usate/non usate\n",
    "    human_df['type'] = human_df['Metaphor'].apply(lambda x: 'unused' if x in unused_set else 'used')\n",
    "    \n",
    "    # Media dei 10 annotatori sintetici\n",
    "    synthetic_mean = synthetic_df.groupby('metaphor')[dimension].mean().reset_index()\n",
    "    \n",
    "    # Annotatore 1\n",
    "    synthetic_1 = synthetic_df[synthetic_df['annotator']==1][['metaphor', dimension]].rename(columns={dimension:'synthetic_1'})\n",
    "    \n",
    "    # Unisci\n",
    "    merged_1 = pd.merge(human_df, synthetic_1, left_on='Metaphor', right_on='metaphor').dropna()\n",
    "    merged_mean = pd.merge(human_df, synthetic_mean, left_on='Metaphor', right_on='metaphor').dropna()\n",
    "    \n",
    "    results = {}\n",
    "    for t in ['used', 'unused']:\n",
    "        sub_1 = merged_1[merged_1['type']==t]\n",
    "        sub_mean = merged_mean[merged_mean['type']==t]\n",
    "        if len(sub_1) > 1:\n",
    "            corr_1, _ = stats.spearmanr(sub_1[dimension], sub_1['synthetic_1'])\n",
    "            corr_mean, _ = stats.spearmanr(sub_mean[dimension], sub_mean[dimension+'_y'])  # mean\n",
    "        else:\n",
    "            corr_1, corr_mean = np.nan, np.nan\n",
    "        results[t] = {'annotator_1': corr_1, 'mean_10': corr_mean}\n",
    "    return results\n",
    "\n",
    "# Lista dimensioni per dataset\n",
    "dimensions = {\n",
    "    \"MB\": [\"FAMILIARITY_human\",\"MEANINGFULNESS_human\",\"BODY_RELATEDNESS_human\"],\n",
    "    \"ME\": [\"FAMILIARITY_human\",\"MEANINGFULNESS_human\",\"DIFFICULTY_human\"],\n",
    "    \"MI\": [\"PHISICALITY_human\",\"IMAGEABILITY_human\"],\n",
    "    \"MM\": [\"FAMILIARITY_human\",\"MEANINGFULNESS_human\"]\n",
    "}\n",
    "\n",
    "# Correlazioni finali\n",
    "all_results = {}\n",
    "\n",
    "for dataset in ['MB','ME','MI','MM']:\n",
    "    human_df = human_dfs[dataset]\n",
    "    synthetic_df = synthetic_dfs[dataset]\n",
    "    \n",
    "    all_results[dataset] = {}\n",
    "    \n",
    "    for dim in dimensions[dataset]:\n",
    "        # rimuovi _human per confronto con sintetico\n",
    "        dim_name = dim.replace(\"_human\",\"\")\n",
    "        unused_set = unused_metaphors[dataset][dim_name]\n",
    "        all_results[dataset][dim_name] = compute_correlations(human_df, synthetic_df, dim, unused_set)\n",
    "\n",
    "# Stampa risultati\n",
    "for dataset, dims in all_results.items():\n",
    "    print(f\"\\nDataset: {dataset}\")\n",
    "    for dim, res in dims.items():\n",
    "        print(f\"  Dimension: {dim}\")\n",
    "        for t, vals in res.items():\n",
    "            print(f\"    {t}: annotator_1={vals['annotator_1']:.3f}, mean_10={vals['mean_10']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143436b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del calcolo del \"cambio di accuratezza\"\n",
    "accuracy_change = {}\n",
    "\n",
    "for dataset, dims in all_results.items():\n",
    "    accuracy_change[dataset] = {}\n",
    "    for dim, res in dims.items():\n",
    "        # Differenza correlazioni (unused - used)\n",
    "        delta_annotator_1 = np.nan\n",
    "        delta_mean_10 = np.nan\n",
    "        if res['used']['annotator_1'] is not None and res['unused']['annotator_1'] is not None:\n",
    "            delta_annotator_1 = res['unused']['annotator_1'] - res['used']['annotator_1']\n",
    "        if res['used']['mean_10'] is not None and res['unused']['mean_10'] is not None:\n",
    "            delta_mean_10 = res['unused']['mean_10'] - res['used']['mean_10']\n",
    "        accuracy_change[dataset][dim] = {'delta_annotator_1': delta_annotator_1, 'delta_mean_10': delta_mean_10}\n",
    "\n",
    "# Stampa dei risultati del cambio di accuratezza\n",
    "print(\"\\n--- Cambio di accuratezza tra metafore non usate e usate ---\")\n",
    "for dataset, dims in accuracy_change.items():\n",
    "    print(f\"\\nDataset: {dataset}\")\n",
    "    for dim, vals in dims.items():\n",
    "        print(f\"  Dimension: {dim}\")\n",
    "        print(f\"    Delta annotator_1: {vals['delta_annotator_1']:.3f}\")\n",
    "        print(f\"    Delta mean_10: {vals['delta_mean_10']:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
